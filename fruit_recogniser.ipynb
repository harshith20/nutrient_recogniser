{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-19T14:58:14.851612Z","iopub.execute_input":"2022-07-19T14:58:14.853016Z","iopub.status.idle":"2022-07-19T14:58:16.466466Z","shell.execute_reply.started":"2022-07-19T14:58:14.852972Z","shell.execute_reply":"2022-07-19T14:58:16.465460Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_files\nfrom tensorflow.python.keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-07-17T10:09:13.759932Z","iopub.execute_input":"2022-07-17T10:09:13.761019Z","iopub.status.idle":"2022-07-17T10:09:24.747321Z","shell.execute_reply.started":"2022-07-17T10:09:13.760973Z","shell.execute_reply":"2022-07-17T10:09:24.746327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading data and putting them into training and test sets\n\n#locations setting for training and test datasets\ntrain_data='/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Training'\ntest_data='/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \nvalues = tf.io.read_file('/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Test/cucumber_1/r0_79.jpg')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creates X_train and Y_train using file_names and folders\ndef load_f(path):\n    data = load_files(path)\n    return data\ndef get_data(path):\n    data = load_f(path)\n    files = np.array(data['filenames'])\n    targets = np.array(data['target'])\n    target_labels = np.array(data['target_names'])\n    \n    return files,targets,target_labels\n\nX_train, Y_train, labels = get_data(train_data)\nX_test, Y_test,_ = get_data(test_data)\nY_train = np_utils.to_categorical(Y_train, 120)\nY_test = np_utils.to_categorical(Y_test, 120)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(filename, image_type, resize_shape, channels):\n    value = tf.io.read_file(filename)\n    if image_type == 'png':\n        decoded_image = tf.image.decode_png(value, channels=channels)\n    elif image_type == 'jpeg':\n        decoded_image = tf.image.decode_jpeg(value, channels=channels)\n    else:\n        decoded_image = tf.image.decode_image(value, channels=channels)\n    \n    if resize_shape is not None and image_type in ['png', 'jpeg']:\n        decoded_image = tf.image.resize(decoded_image, resize_shape)\n    \n    return decoded_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_dataset(image_paths, image_type, resize_shape, channels):\n    filename_tensor = tf.constant(image_paths)\n    dataset = tf.data.Dataset.from_tensor_slices(filename_tensor)\n    \n    def _map_fn(filename):\n        decode_images = decode_image(filename, image_type, resize_shape, channels=channels)\n        return decode_images\n    \n    map_dataset = dataset.map(_map_fn) # we use the map method: allow to apply the function _map_fn to all the \n    # elements of dataset \n    return map_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_data(image_paths, image_type, resize_shape, channels):\n    dataset = get_dataset(image_paths, image_type, resize_shape, channels)\n    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n    next_image = iterator.get_next()\n    \n    return next_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=33)\nY_train, Y_val = train_test_split(Y_train, test_size=0.2, random_state=33)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        images_as_array.append(img_to_array(load_img(file)).astype(np.float16))\n        gc.collect()\n        #print(images_as_array[-1])\n    return images_as_array\n\nX_train = np.array(get_image_data(X_train,'jpg',0,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_val = (get_image_data(X_val,'jpg',0,0))\nX_test =(get_image_data(X_test,'jpg',0,0))\nz=get_image_data(['/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Test/cucumber_1/r0_95.jpg'],'jpg',0,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z=get_image_data('/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Test/cucumber_1/r0_95.jpg','jpg',0,0)\nz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.data.Dataset.list_files(X_train, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_ds=tf.data.Dataset.list_files(X_val, shuffle=False)\ntest_ds=tf.data.Dataset.list_files(X_test, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_image(file_path):\n    label = get_label(file_path)\n    img = tf.io.read_file(file_path) # load the raw data from the file as a string\n    img = tf.image.decode_jpeg(img)\n    img = tf.image.resize(img, [128, 128])\n    return img,label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(file_path):\n    import os\n    parts = tf.strings.split(file_path, os.path.sep)\n    return parts[-2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image=process_image(b'/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Training/apple_6/r0_14.jpg')\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_ds = tf.data.Dataset.list_files('/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Training/*/*', shuffle=False)\nimage_count=len(images_ds)\ntrain_size = int(image_count*0.8)\ntrain_ds = images_ds.take(train_size)\ntest_ds = images_ds.skip(train_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = tf.cast(image,'float32')\nplt.imshow(image.eval())\nplt.show()\n# images_ds = images_ds.shuffle(200)\n# for file in images_ds.take(3):\n#     print(file.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_ds.map(process_image)\n#valid_ds = valid_ds.map(process_image)\ntest_ds  = test_ds.map(process_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, label in train_ds.take(5):\n    print(\"****Image: \",image.numpy()[0][0])\n    print(\"****Label: \",label.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.astype('float32')/255\nX_val = X_val.astype('float32')/255\nX_test = X_test.astype('float32')/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load training and validation sets\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nds_train_ = image_dataset_from_directory(\n    '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training',\n    \n    validation_split=0.2,\n    subset=\"training\",\n    seed=13,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training',\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=13,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T15:00:16.134063Z","iopub.execute_input":"2022-07-19T15:00:16.135138Z","iopub.status.idle":"2022-07-19T15:00:20.236645Z","shell.execute_reply.started":"2022-07-19T15:00:16.135090Z","shell.execute_reply":"2022-07-19T15:00:20.234861Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pathlib\ndata_dir='/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training'\ndata_dir=pathlib.Path(data_dir)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T16:38:25.676226Z","iopub.execute_input":"2022-07-19T16:38:25.676664Z","iopub.status.idle":"2022-07-19T16:38:25.681969Z","shell.execute_reply.started":"2022-07-19T16:38:25.676630Z","shell.execute_reply":"2022-07-19T16:38:25.680783Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class_names = (sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T17:21:21.036633Z","iopub.execute_input":"2022-07-19T17:21:21.037090Z","iopub.status.idle":"2022-07-19T17:21:21.049512Z","shell.execute_reply.started":"2022-07-19T17:21:21.037043Z","shell.execute_reply":"2022-07-19T17:21:21.048198Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for image, label in ds_train.take(5):\n    print(\"****Image: \",image.numpy()[0][0])\n    print(\"****Label: \",label.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_files\nfrom tensorflow import keras\nfrom tensorflow.python.keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport gc\n\nfrom sklearn.model_selection import RandomizedSearchCV, KFold,GridSearchCV\n","metadata":{"execution":{"iopub.status.busy":"2022-07-19T14:59:56.510037Z","iopub.execute_input":"2022-07-19T14:59:56.510415Z","iopub.status.idle":"2022-07-19T15:00:07.556374Z","shell.execute_reply.started":"2022-07-19T14:59:56.510382Z","shell.execute_reply":"2022-07-19T15:00:07.555101Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade tensorflow\n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T06:56:47.454372Z","iopub.execute_input":"2022-07-17T06:56:47.455566Z","iopub.status.idle":"2022-07-17T06:57:02.900987Z","shell.execute_reply.started":"2022-07-17T06:56:47.455477Z","shell.execute_reply":"2022-07-17T06:57:02.900126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# detect and init the TPU\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\n #tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# tf.config.experimental_run_functions_eagerly(True)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\n\n\nmodel = keras.Sequential([\n\n# Attach a global average pooling layer after the base\nlayers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=[128, 128, 3]),\nlayers.experimental.preprocessing.RandomRotation(0.1),\nlayers.experimental.preprocessing.RandomZoom(0.1),\nlayers.experimental.preprocessing.Rescaling(1./255, input_shape=([128, 128, 3])),\nlayers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n              input_shape=[128, 128, 3]),\nlayers.MaxPool2D(),\n\n# Block Two\nlayers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\nlayers.MaxPool2D(),\n\n# Block Three\n# YOUR CODE HERE\nlayers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\nlayers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\nlayers.MaxPool2D(),\n\n# Head\nlayers.Flatten(),\nlayers.Dense(30, activation='relu'),\nlayers.Dropout(0.2),\nlayers.Dense(30, activation='relu'),\nlayers.Dropout(0.2),\nlayers.Dense(131, activation='sigmoid')\n])\n\nmodel.compile(\noptimizer='adam',\n# YOUR CODE HERE: Add loss and metric\nloss='categorical_crossentropy',\nmetrics=['accuracy']\n)\n \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-19T15:00:29.029373Z","iopub.execute_input":"2022-07-19T15:00:29.029781Z","iopub.status.idle":"2022-07-19T15:00:29.352200Z","shell.execute_reply.started":"2022-07-19T15:00:29.029749Z","shell.execute_reply":"2022-07-19T15:00:29.351115Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# detect and init the TPU\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\n#tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n#tf.config.experimental_run_functions_eagerly(True)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():  \n    model = keras.Sequential([\n\n# Attach a global average pooling layer after the base\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=[128, 128, 3]),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n    layers.experimental.preprocessing.Rescaling(1./255, input_shape=([128, 128, 3])),\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[128, 128, 3]),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    # YOUR CODE HERE\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(30, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(30, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(131, activation='sigmoid')\n    ])\n\n    model.compile(\n    optimizer='adam',\n    # YOUR CODE HERE: Add loss and metric\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n    )","metadata":{"execution":{"iopub.status.busy":"2022-07-17T07:48:19.457491Z","iopub.execute_input":"2022-07-17T07:48:19.458015Z","iopub.status.idle":"2022-07-17T07:48:25.921738Z","shell.execute_reply.started":"2022-07-17T07:48:19.457960Z","shell.execute_reply":"2022-07-17T07:48:25.920720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T16:42:57.443311Z","iopub.execute_input":"2022-07-18T16:42:57.444651Z","iopub.status.idle":"2022-07-18T16:42:57.454880Z","shell.execute_reply.started":"2022-07-18T16:42:57.444588Z","shell.execute_reply":"2022-07-18T16:42:57.453689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(ds_train,\n        batch_size = 128,\n        epochs=3,\n        validation_data=ds_valid,\n        verbose=2,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T15:00:51.136047Z","iopub.execute_input":"2022-07-19T15:00:51.136433Z","iopub.status.idle":"2022-07-19T15:57:42.631194Z","shell.execute_reply.started":"2022-07-19T15:00:51.136403Z","shell.execute_reply":"2022-07-19T15:57:42.629973Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\n\n\nmodel.save('my_model.h5')\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-17T16:59:07.422090Z","iopub.execute_input":"2022-07-17T16:59:07.422848Z","iopub.status.idle":"2022-07-17T16:59:07.509001Z","shell.execute_reply.started":"2022-07-17T16:59:07.422810Z","shell.execute_reply":"2022-07-17T16:59:07.507867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import plot\nimport pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_test_=image_dataset_from_directory(\n    '/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Test',\n    labels='inferred',\n    label_mode='categorical',\n    image_size=[128, 128],\n    interpolation='nearest',\n    shuffle=True,\n)\nds_test = (\n    ds_test_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\ndef create_model(layers,activation):\n    model=keras.sequential()\n    for i,nodes in enumerate(layers):\n        if i==0:\n            model.add(RandomFlip(\"horizontal\",\n                      input_shape=[128, 128, 3]))\n            model.add(RandomRotation(0.1))\n            model.add(RandomZoom(0.1))\n            model.add(Rescaling(1./255, input_shape=([128, 128, 3])))\n            model.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                          input_shape=[128, 128, 3]))\n            model.add(MaxPool2D())\n\n            # Block Two\n            model.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\n            model.add(MaxPool2D())\n\n            # Block Three\n            # YOUR CODE HERE\n            model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n            model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n            model.add(MaxPool2D())\n\n            # Head\n            model.add(Flatten())\n        else :\n            model.add(dense(nodes, activation='relu'))\n            layers.Dropout(0.2)\n        model.add(dense(131, activation='sigmoid'))    \n    model.compile(\n    optimizer='adam',\n    # YOUR CODE HERE: Add loss and metric\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n    return model\nmodel=tf.keras.wrappers.scikit_learn.KerasClassifier(batch_size = 128,\n        validation_data=ds_valid,verbose=2, shuffle=True,build_fn=create_model)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T17:59:13.879438Z","iopub.execute_input":"2022-07-16T17:59:13.880300Z","iopub.status.idle":"2022-07-16T17:59:13.932464Z","shell.execute_reply.started":"2022-07-16T17:59:13.880252Z","shell.execute_reply":"2022-07-16T17:59:13.931211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layers=[[32],[64,32,32],[64,32]]\nparam = dict(layers=layers,epochs=[10])\nX,y=ds_train.next()\n\nrf_random = GridSearchCV(estimator = model,param_grid = param)\ngrid_result=rf_random.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = tf.keras.utils.load_img('/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test/Pineapple Mini/r_208_100.jpg'\n    , target_size=(128, 128)\n)\nimg_array = convert_to_float(img,'Pineapple')\nimg_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = tf.keras.utils.load_img('/kaggle/input/fruits/fruits-360_dataset/fruits-360/Test/Chestnut/r2_116_100.jpg'\n    , target_size=(128, 128,3)\n)\nimg_array = tf.keras.utils.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) \n#img_array=tf.keras.layers.Rescaling(1./255)(img_array)\nprint(img_array)\npredictions=model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)\nprint(score)\n# for image, label in ds_test.take(1):\n#     #print(\"****Image: \",image.numpy()[0][0])\n#      print(\"****Label: \",label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-07-19T16:59:31.507093Z","iopub.execute_input":"2022-07-19T16:59:31.507492Z","iopub.status.idle":"2022-07-19T16:59:31.601694Z","shell.execute_reply.started":"2022-07-19T16:59:31.507463Z","shell.execute_reply":"2022-07-19T16:59:31.600152Z"},"trusted":true},"execution_count":17,"outputs":[]}]}